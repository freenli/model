{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd, numpy as np\n",
    "import sklearn.metrics as skm\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_path = \"./quda_corpus.txt\"\n",
    "\n",
    "lable_typies =['Retrieve Value',\n",
    "     'Filter',\n",
    "     'Compute Derived Value',\n",
    "     'Find Extremum',\n",
    "     'Sort',\n",
    "     'Determine Range',\n",
    "     'Characterize Distribution',\n",
    "     'Find Anomalies',\n",
    "     'Cluster',\n",
    "     'Correlate']\n",
    "\n",
    "num_labels = len(lable_typies)\n",
    "\n",
    "split_info = {\n",
    "    \"random\": False,\n",
    "    \"expert\": [20, 4],\n",
    "    \"bundle\": [920, 1],\n",
    "    \"table\": [36, 3]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_df(data1, data2=None):\n",
    "    \n",
    "    data1_df = []\n",
    "\n",
    "    for i in data1:\n",
    "        for j in i:\n",
    "            data1_df.append({\"text\": j[0], \"labels\": j[1]})\n",
    "\n",
    "    if data2:\n",
    "        data2_df = []\n",
    "        for i in data2:\n",
    "            for j in i:\n",
    "                data2_df.append({\"text\": j[0], \"labels\": j[1]})\n",
    "\n",
    "        return pd.DataFrame(shuffle(data1_df)), pd.DataFrame(shuffle(data2_df))\n",
    "\n",
    "    return pd.DataFrame(shuffle(data1_df))\n",
    "\n",
    "\n",
    "def dataset_split(data_path, split_type, test_size=0.2):\n",
    "    ''' Retrun a train set and a test set after specified a certain data-split type\n",
    "        Args:\n",
    "            data_path: The path of Quda corpus\n",
    "            split_type: 'random', 'expert', 'bundle', or 'table'.\n",
    "            test_size: The proportion of the dataset to include in the test split\n",
    "    '''\n",
    "    \n",
    "    split = split_info[split_type]\n",
    "    if split:\n",
    "        [num, pi] = split\n",
    "        data = [[] for i in range(num)]\n",
    "        \n",
    "        with open(data_path, \"r\", encoding='utf-8') as fp:\n",
    "            for line in fp.readlines():\n",
    "                word = line.split()\n",
    "                info = word[0].split(\":\")\n",
    "                typeId = json.loads(info[0])\n",
    "                query = \" \".join(word[1:])\n",
    "                index = int(info[pi]) - 1\n",
    "                labels = [0] * num_labels\n",
    "                for i in range(len(typeId)):\n",
    "                    labels[typeId[i]-1] = 1\n",
    "                \n",
    "                data[index].append([query,labels])\n",
    "                \n",
    "\n",
    "        for i in range(num):\n",
    "            data[i] = shuffle(data[i])\n",
    "            data[i] = np.asarray(data[i])\n",
    "\n",
    "        data = shuffle(data)\n",
    "        \n",
    "        train_s, test_s = train_test_split(data, test_size=test_size)\n",
    "        print(\"The number of %ss for train: %d; for test: %d\" % (split_type, len(train_s), len(test_s)))\n",
    "        \n",
    "        train_set, test_set = transform_df(train_s, test_s)\n",
    "        print(\"The number of queries for train: %d; for test: %d\" % (len(train_set), len(test_set)))\n",
    "        \n",
    "        return train_set, test_set\n",
    "    \n",
    "    data = []\n",
    "    with open(data_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f.readlines():\n",
    "            word = line.split()\n",
    "            info = word[0].split(\":\")\n",
    "            typeId = json.loads(info[0])\n",
    "            query = \" \".join(word[1:])\n",
    "            labels = [0] * num_labels\n",
    "            for i in range(len(typeId)):\n",
    "                labels[typeId[i]-1] = 1\n",
    "            data.append([query,labels])\n",
    "    data = shuffle(data)\n",
    "    \n",
    "    train_s, test_s = train_test_split(data, test_size=test_size)\n",
    "    train_set = pd.DataFrame(train_s,columns=[\"text\", \"labels\"])\n",
    "    test_set = pd.DataFrame(test_s,columns=[\"text\", \"labels\"])\n",
    "    print(\"The number of queries for train: %d; for test: %d\" % (len(train_set), len(test_set)))\n",
    "    \n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of tables for train: 28; for test: 8\n",
      "The number of queries for train: 11093; for test: 2942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\miniconda\\envs\\st_gpu\\lib\\site-packages\\numpy\\core\\_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "# There are four types for spliting Quda corpus: random, expert, bundle, and table.\n",
    "train_set, test_set = dataset_split(corpus_path, \"table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what is the average height of the floors on th...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the students ' scores in the cw2 were what ran...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what they want to know is what football tactic...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>are there any regions with extremely low hf po...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for o3 , what is the distribution value ?</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11088</th>\n",
       "      <td>how is the population of a given country relat...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11089</th>\n",
       "      <td>can we group the russian cities on the basis o...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11090</th>\n",
       "      <td>are there any outliers in the correlation betw...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 1, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11091</th>\n",
       "      <td>what was the national distribution of postgrad...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11092</th>\n",
       "      <td>re -arrange the table by adding newset records...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11093 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "0      what is the average height of the floors on th...   \n",
       "1      the students ' scores in the cw2 were what ran...   \n",
       "2      what they want to know is what football tactic...   \n",
       "3      are there any regions with extremely low hf po...   \n",
       "4              for o3 , what is the distribution value ?   \n",
       "...                                                  ...   \n",
       "11088  how is the population of a given country relat...   \n",
       "11089  can we group the russian cities on the basis o...   \n",
       "11090  are there any outliers in the correlation betw...   \n",
       "11091  what was the national distribution of postgrad...   \n",
       "11092  re -arrange the table by adding newset records...   \n",
       "\n",
       "                               labels  \n",
       "0      [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1      [0, 1, 0, 0, 0, 1, 0, 0, 0, 0]  \n",
       "2      [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]  \n",
       "3      [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]  \n",
       "4      [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]  \n",
       "...                               ...  \n",
       "11088  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]  \n",
       "11089  [0, 1, 0, 0, 0, 0, 0, 0, 1, 0]  \n",
       "11090  [0, 0, 1, 0, 0, 0, 0, 1, 0, 1]  \n",
       "11091  [0, 1, 0, 0, 0, 0, 1, 0, 0, 0]  \n",
       "11092  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]  \n",
       "\n",
       "[11093 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how many likes does the video \" plush - bad un...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>can you tell me if videos with longer names re...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what language was the book \" the art of super ...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>can you tell me how many likes the video \" plu...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>can you buy a transfer player for less than hi...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2937</th>\n",
       "      <td>the video had already been trending before the...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2938</th>\n",
       "      <td>can you find all the videos that received more...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2939</th>\n",
       "      <td>determine the distribution of male and female ...</td>\n",
       "      <td>[0, 1, 1, 0, 0, 0, 1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2940</th>\n",
       "      <td>which company is the company that published \" ...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2941</th>\n",
       "      <td>as the release year increases , does the reven...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2942 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "0     how many likes does the video \" plush - bad un...   \n",
       "1     can you tell me if videos with longer names re...   \n",
       "2     what language was the book \" the art of super ...   \n",
       "3     can you tell me how many likes the video \" plu...   \n",
       "4     can you buy a transfer player for less than hi...   \n",
       "...                                                 ...   \n",
       "2937  the video had already been trending before the...   \n",
       "2938  can you find all the videos that received more...   \n",
       "2939  determine the distribution of male and female ...   \n",
       "2940  which company is the company that published \" ...   \n",
       "2941  as the release year increases , does the reven...   \n",
       "\n",
       "                              labels  \n",
       "0     [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]  \n",
       "2     [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "3     [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "4     [0, 1, 0, 0, 0, 0, 0, 1, 0, 0]  \n",
       "...                              ...  \n",
       "2937  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]  \n",
       "2938  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "2939  [0, 1, 1, 0, 0, 0, 1, 0, 0, 0]  \n",
       "2940  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "2941  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]  \n",
       "\n",
       "[2942 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_seq_length = int(max(train_set[\"text\"].str.split().str.len().max(), test_set[\"text\"].str.split().str.len().max()))\n",
    "max_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMultiLabelSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForMultiLabelSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMultiLabelSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMultiLabelSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from simpletransformers.classification import MultiLabelClassificationModel\n",
    "\n",
    "# initialize a model\n",
    "model = MultiLabelClassificationModel('bert', 'bert-base-cased', num_labels=num_labels, use_cuda=True, args={\n",
    "    'train_batch_size': 4, \n",
    "    'gradient_accumulation_steps': 8, \n",
    "    'learning_rate': 3e-5, \n",
    "    'num_train_epochs': 3, \n",
    "    'max_seq_length': max_seq_length, # 41\n",
    "    'fp16': False\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b46f08f682174954b7e6996ce07dc29b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11093.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cec88bbf39844fe9b287ff3b6e1da4e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=3.0, style=ProgressStyle(description_width='iâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f017e7f76ead4e369a04b390320a2a65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Running Epoch 0 of 3', max=2774.0, style=ProgressStyle(deâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "798dc520e4404c319dcf3c99c7533cb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Running Epoch 1 of 3', max=2774.0, style=ProgressStyle(deâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70190d09dbb74595974006dea2664db9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Running Epoch 2 of 3', max=2774.0, style=ProgressStyle(deâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "model.train_model(train_set) \n",
    "\n",
    "# load a model from outpus directory\n",
    "# model = MultiLabelClassificationModel('bert', 'outputs/', num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0195b83283c54e599a03d1dc2181ed79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2942.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ad7ffad389249a49a7dc08d861e9597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=368.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "preds, outputs = model.predict(test_set.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[2507  107]\n",
      "  [ 124  204]]\n",
      "\n",
      " [[1668  249]\n",
      "  [ 309  716]]\n",
      "\n",
      " [[2493   72]\n",
      "  [ 151  226]]\n",
      "\n",
      " [[2473   41]\n",
      "  [  57  371]]\n",
      "\n",
      " [[2713    6]\n",
      "  [  20  203]]\n",
      "\n",
      " [[2688    7]\n",
      "  [ 112  135]]\n",
      "\n",
      " [[2686   17]\n",
      "  [  43  196]]\n",
      "\n",
      " [[2586   51]\n",
      "  [  74  231]]\n",
      "\n",
      " [[2713    7]\n",
      "  [  35  187]]\n",
      "\n",
      " [[2477   50]\n",
      "  [  65  350]]]\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "           Retrieve Value       0.66      0.62      0.64       328\n",
      "                   Filter       0.74      0.70      0.72      1025\n",
      "    Compute Derived Value       0.76      0.60      0.67       377\n",
      "            Find Extremum       0.90      0.87      0.88       428\n",
      "                     Sort       0.97      0.91      0.94       223\n",
      "          Determine Range       0.95      0.55      0.69       247\n",
      "Characterize Distribution       0.92      0.82      0.87       239\n",
      "           Find Anomalies       0.82      0.76      0.79       305\n",
      "                  Cluster       0.96      0.84      0.90       222\n",
      "                Correlate       0.88      0.84      0.86       415\n",
      "\n",
      "                micro avg       0.82      0.74      0.78      3809\n",
      "                macro avg       0.86      0.75      0.80      3809\n",
      "             weighted avg       0.83      0.74      0.78      3809\n",
      "              samples avg       0.80      0.77      0.77      3809\n",
      "\n",
      "accuracy_score: 0.652277\n",
      "f1_score: 0.779267\n",
      "fbeta_score: 0.804831\n",
      "hamming_loss: 0.054283\n",
      "jaccard_score: 0.638361\n",
      "precision_score: 0.822825\n",
      "recall_score: 0.740089\n",
      "zero_one_loss: 0.347723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\miniconda\\envs\\st_gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# evaluate the results\n",
    "y_true = list(test_set.labels)\n",
    "y_pred = np.array(preds)\n",
    "cm = skm.multilabel_confusion_matrix(y_true, y_pred)\n",
    "print(cm)\n",
    "print( skm.classification_report(y_true,y_pred, target_names=lable_typies))\n",
    "print(\"accuracy_score: %f\" % skm.accuracy_score(y_true,y_pred))\n",
    "print(\"f1_score: %f\" % skm.f1_score(y_true,y_pred,average='micro'))\n",
    "print(\"fbeta_score: %f\" % skm.fbeta_score(y_true,y_pred, average='micro', beta=0.5))\n",
    "print(\"hamming_loss: %f\" % skm.hamming_loss(y_true,y_pred))\n",
    "print(\"jaccard_score: %f\" % skm.jaccard_score(y_true,y_pred, average='micro'))\n",
    "print(\"precision_score: %f\" % skm.precision_score(y_true,y_pred, average='micro'))\n",
    "print(\"recall_score: %f\" % skm.recall_score(y_true,y_pred, average='micro'))\n",
    "print(\"zero_one_loss: %f\" % skm.zero_one_loss(y_true,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "st_gpu",
   "language": "python",
   "name": "st_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
