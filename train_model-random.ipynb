{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd, numpy as np\n",
    "import sklearn.metrics as skm\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_path = \"./quda_corpus.txt\"\n",
    "\n",
    "lable_typies =['Retrieve Value',\n",
    "     'Filter',\n",
    "     'Compute Derived Value',\n",
    "     'Find Extremum',\n",
    "     'Sort',\n",
    "     'Determine Range',\n",
    "     'Characterize Distribution',\n",
    "     'Find Anomalies',\n",
    "     'Cluster',\n",
    "     'Correlate']\n",
    "\n",
    "num_labels = len(lable_typies)\n",
    "\n",
    "split_info = {\n",
    "    \"random\": False,\n",
    "    \"expert\": [20, 4],\n",
    "    \"bundle\": [920, 1],\n",
    "    \"table\": [36, 3]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_df(data1, data2=None):\n",
    "    \n",
    "    data1_df = []\n",
    "\n",
    "    for i in data1:\n",
    "        for j in i:\n",
    "            data1_df.append({\"text\": j[0], \"labels\": j[1]})\n",
    "\n",
    "    if data2:\n",
    "        data2_df = []\n",
    "        for i in data2:\n",
    "            for j in i:\n",
    "                data2_df.append({\"text\": j[0], \"labels\": j[1]})\n",
    "\n",
    "        return pd.DataFrame(shuffle(data1_df)), pd.DataFrame(shuffle(data2_df))\n",
    "\n",
    "    return pd.DataFrame(shuffle(data1_df))\n",
    "\n",
    "\n",
    "def dataset_split(data_path, split_type, test_size=0.2):\n",
    "    ''' Retrun a train set and a test set after specified a certain data-split type\n",
    "        Args:\n",
    "            data_path: The path of Quda corpus\n",
    "            split_type: 'random', 'expert', 'bundle', or 'table'.\n",
    "            test_size: The proportion of the dataset to include in the test split\n",
    "    '''\n",
    "    \n",
    "    split = split_info[split_type]\n",
    "    if split:\n",
    "        [num, pi] = split\n",
    "        data = [[] for i in range(num)]\n",
    "        \n",
    "        with open(data_path, \"r\", encoding='utf-8') as fp:\n",
    "            for line in fp.readlines():\n",
    "                word = line.split()\n",
    "                info = word[0].split(\":\")\n",
    "                typeId = json.loads(info[0])\n",
    "                query = \" \".join(word[1:])\n",
    "                index = int(info[pi]) - 1\n",
    "                labels = [0] * num_labels\n",
    "                for i in range(len(typeId)):\n",
    "                    labels[typeId[i]-1] = 1\n",
    "                \n",
    "                data[index].append([query,labels])\n",
    "                \n",
    "\n",
    "        for i in range(num):\n",
    "            data[i] = shuffle(data[i])\n",
    "            data[i] = np.asarray(data[i])\n",
    "\n",
    "        data = shuffle(data)\n",
    "        \n",
    "        train_s, test_s = train_test_split(data, test_size=test_size)\n",
    "        print(\"The number of %ss for train: %d; for test: %d\" % (split_type, len(train_s), len(test_s)))\n",
    "        \n",
    "        train_set, test_set = transform_df(train_s, test_s)\n",
    "        print(\"The number of queries for train: %d; for test: %d\" % (len(train_set), len(test_set)))\n",
    "        \n",
    "        return train_set, test_set\n",
    "    \n",
    "    data = []\n",
    "    with open(data_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f.readlines():\n",
    "            word = line.split()\n",
    "            info = word[0].split(\":\")\n",
    "            typeId = json.loads(info[0])\n",
    "            query = \" \".join(word[1:])\n",
    "            labels = [0] * num_labels\n",
    "            for i in range(len(typeId)):\n",
    "                labels[typeId[i]-1] = 1\n",
    "            data.append([query,labels])\n",
    "    data = shuffle(data)\n",
    "    \n",
    "    train_s, test_s = train_test_split(data, test_size=test_size)\n",
    "    train_set = pd.DataFrame(train_s,columns=[\"text\", \"labels\"])\n",
    "    test_set = pd.DataFrame(test_s,columns=[\"text\", \"labels\"])\n",
    "    print(\"The number of queries for train: %d; for test: %d\" % (len(train_set), len(test_set)))\n",
    "    \n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of queries for train: 11228; for test: 2807\n"
     ]
    }
   ],
   "source": [
    "# There are four types for spliting Quda corpus: random, expert, bundle, and table.\n",
    "train_set, test_set = dataset_split(corpus_path, \"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>calculate the quality of o3 .</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>records with na values are to be removed</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>taking all the free gaming apps , what is the ...</td>\n",
       "      <td>[0, 1, 1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>using a chosen year of release as cluster para...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>show me the station that is the southernmost .</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11223</th>\n",
       "      <td>has there been any correlation made between th...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11224</th>\n",
       "      <td>locate all regions with a number of missing re...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11225</th>\n",
       "      <td>how do boys and girls cw2 scores differ ?</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11226</th>\n",
       "      <td>how about the correlation between age and trav...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11227</th>\n",
       "      <td>tell me the average gdp of the nations compris...</td>\n",
       "      <td>[0, 1, 1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11228 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "0                          calculate the quality of o3 .   \n",
       "1               records with na values are to be removed   \n",
       "2      taking all the free gaming apps , what is the ...   \n",
       "3      using a chosen year of release as cluster para...   \n",
       "4         show me the station that is the southernmost .   \n",
       "...                                                  ...   \n",
       "11223  has there been any correlation made between th...   \n",
       "11224  locate all regions with a number of missing re...   \n",
       "11225          how do boys and girls cw2 scores differ ?   \n",
       "11226  how about the correlation between age and trav...   \n",
       "11227  tell me the average gdp of the nations compris...   \n",
       "\n",
       "                               labels  \n",
       "0      [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]  \n",
       "1      [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "2      [0, 1, 1, 0, 0, 0, 0, 0, 0, 0]  \n",
       "3      [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]  \n",
       "4      [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]  \n",
       "...                               ...  \n",
       "11223  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]  \n",
       "11224  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "11225  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]  \n",
       "11226  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]  \n",
       "11227  [0, 1, 1, 0, 0, 0, 0, 0, 0, 0]  \n",
       "\n",
       "[11228 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>are there any clusters of countries in terms o...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>does it appear more likes are given to videos ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>could you please enumerate the books written b...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is there a correlation between life expectancy...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>do you have to pay money for \" coloring book m...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2802</th>\n",
       "      <td>give me videos that have received dislikes .</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2803</th>\n",
       "      <td>organize all these things by the reviews they ...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2804</th>\n",
       "      <td>looking through the suicide rates , do any out...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2805</th>\n",
       "      <td>i would like to sort all the counties in conne...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2806</th>\n",
       "      <td>show me only actors who are older than 30 .</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2807 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "0     are there any clusters of countries in terms o...   \n",
       "1     does it appear more likes are given to videos ...   \n",
       "2     could you please enumerate the books written b...   \n",
       "3     is there a correlation between life expectancy...   \n",
       "4     do you have to pay money for \" coloring book m...   \n",
       "...                                                 ...   \n",
       "2802       give me videos that have received dislikes .   \n",
       "2803  organize all these things by the reviews they ...   \n",
       "2804  looking through the suicide rates , do any out...   \n",
       "2805  i would like to sort all the counties in conne...   \n",
       "2806        show me only actors who are older than 30 .   \n",
       "\n",
       "                              labels  \n",
       "0     [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]  \n",
       "1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]  \n",
       "2     [0, 1, 0, 0, 0, 1, 0, 0, 0, 0]  \n",
       "3     [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]  \n",
       "4     [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "...                              ...  \n",
       "2802  [0, 1, 0, 0, 0, 0, 0, 1, 0, 0]  \n",
       "2803  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]  \n",
       "2804  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]  \n",
       "2805  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]  \n",
       "2806  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "\n",
       "[2807 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_seq_length = int(max(train_set[\"text\"].str.split().str.len().max(), test_set[\"text\"].str.split().str.len().max()))\n",
    "max_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMultiLabelSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForMultiLabelSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMultiLabelSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMultiLabelSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from simpletransformers.classification import MultiLabelClassificationModel\n",
    "\n",
    "# initialize a model\n",
    "model = MultiLabelClassificationModel('bert', 'bert-base-cased', num_labels=num_labels, use_cuda=True, args={\n",
    "    'train_batch_size': 4, \n",
    "    'gradient_accumulation_steps': 8, \n",
    "    'learning_rate': 3e-5, \n",
    "    'num_train_epochs': 3, \n",
    "    'max_seq_length': max_seq_length, # 41\n",
    "    'fp16': False\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8152873dee58402baccff1e8a21126c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11228.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1ec6844997e462a96d547d3484185b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=3.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dec2e3a96ef427c80c380b729733078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Running Epoch 0 of 3', max=2807.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a738fc7f97cd441199fd2041cd193e91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Running Epoch 1 of 3', max=2807.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed3008acaccb4b84815895d1ede33a78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Running Epoch 2 of 3', max=2807.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "model.train_model(train_set) \n",
    "\n",
    "# load a model from outpus directory\n",
    "# model = MultiLabelClassificationModel('bert', 'outputs/', num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "459d3767ce784da08a5671774110cdd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2807.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b59f5b93fb854c54a5f19b45933376f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=351.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "preds, outputs = model.predict(test_set.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[2543    3]\n",
      "  [  11  250]]\n",
      "\n",
      " [[1853    8]\n",
      "  [  20  926]]\n",
      "\n",
      " [[2382   13]\n",
      "  [  22  390]]\n",
      "\n",
      " [[2375   12]\n",
      "  [  10  410]]\n",
      "\n",
      " [[2524    8]\n",
      "  [   9  266]]\n",
      "\n",
      " [[2534    5]\n",
      "  [  22  246]]\n",
      "\n",
      " [[2525    1]\n",
      "  [  18  263]]\n",
      "\n",
      " [[2536    5]\n",
      "  [  13  253]]\n",
      "\n",
      " [[2569    5]\n",
      "  [   7  226]]\n",
      "\n",
      " [[2464    1]\n",
      "  [  10  332]]]\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "           Retrieve Value       0.99      0.96      0.97       261\n",
      "                   Filter       0.99      0.98      0.99       946\n",
      "    Compute Derived Value       0.97      0.95      0.96       412\n",
      "            Find Extremum       0.97      0.98      0.97       420\n",
      "                     Sort       0.97      0.97      0.97       275\n",
      "          Determine Range       0.98      0.92      0.95       268\n",
      "Characterize Distribution       1.00      0.94      0.97       281\n",
      "           Find Anomalies       0.98      0.95      0.97       266\n",
      "                  Cluster       0.98      0.97      0.97       233\n",
      "                Correlate       1.00      0.97      0.98       342\n",
      "\n",
      "                micro avg       0.98      0.96      0.97      3704\n",
      "                macro avg       0.98      0.96      0.97      3704\n",
      "             weighted avg       0.98      0.96      0.97      3704\n",
      "              samples avg       0.98      0.97      0.97      3704\n",
      "\n",
      "accuracy_score: 0.944781\n",
      "f1_score: 0.972294\n",
      "fbeta_score: 0.978787\n",
      "hamming_loss: 0.007232\n",
      "jaccard_score: 0.946082\n",
      "precision_score: 0.983163\n",
      "recall_score: 0.961663\n",
      "zero_one_loss: 0.055219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\miniconda\\envs\\st_gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# evaluate the results\n",
    "y_true = list(test_set.labels)\n",
    "y_pred = np.array(preds)\n",
    "cm = skm.multilabel_confusion_matrix(y_true, y_pred)\n",
    "print(cm)\n",
    "print( skm.classification_report(y_true,y_pred, target_names=lable_typies))\n",
    "print(\"accuracy_score: %f\" % skm.accuracy_score(y_true,y_pred))\n",
    "print(\"f1_score: %f\" % skm.f1_score(y_true,y_pred,average='micro'))\n",
    "print(\"fbeta_score: %f\" % skm.fbeta_score(y_true,y_pred, average='micro', beta=0.5))\n",
    "print(\"hamming_loss: %f\" % skm.hamming_loss(y_true,y_pred))\n",
    "print(\"jaccard_score: %f\" % skm.jaccard_score(y_true,y_pred, average='micro'))\n",
    "print(\"precision_score: %f\" % skm.precision_score(y_true,y_pred, average='micro'))\n",
    "print(\"recall_score: %f\" % skm.recall_score(y_true,y_pred, average='micro'))\n",
    "print(\"zero_one_loss: %f\" % skm.zero_one_loss(y_true,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "st_gpu",
   "language": "python",
   "name": "st_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
